# Recvis final project : 

## Abstract 

Self-supervised learning using transformers \cite{dosovitskiy2021image} has shown interesting emerging properties \cite{caron2021emerging} and learn rich embeddings without annotations. Most recently, Barlow Twins \cite{DBLP:journals/corr/abs-2103-03230} proposed an elegant self-supervised learning technique using a ResNet50 backbone which achieved competitive results when fine-tuned on downstream tasks. The network learns deep image embeddings based on a cross correlation loss which pushes a similarity between the embeddings of two crops of the same image. We propose to study a transformer based Barlow Twins architecture, while analyzing the learned embeddings and testing our method on semantic segmentation tasks. Our goal is to check the reputability of the relevant attention maps produced by \cite{caron2021emerging} using the self supervised training method proposed in Barlow Twins. Then, we want to use such attention maps (either from DINO or our experiment) in order to assist the segmentation and create a new attention aware decoding architecture. 


## Project proposal 


# TO DO : 

- [ ] Define metric and baseline to compare our architectures 
- [ ] Download dataset and create dataloader 
- [ ] Create Transformer network
- [ ] Create BarlowTwins agent 
- [ ] Implement feature map visualization 

## Defining baseline : 

### 1. Emerging properties of self supervise learning and attention 

Here no baseline is required, this is mostly a visual evaluation but we could invent a metric of how significant the attention heads are, how much information they carry, and thus could create a loss to push the attention heads to learn even more meaningful attentino maps. 


### 2. Semantic Segmentation on COCOStuff

Our goal is to design a new semantic segmentation head which uses the attention maps. We could look for inspiration from the most recent **SegFormer** paper which implements

We will use the following evaluations  :
- Barlow twins with resnet 50 + semantic segmentation head without attention maps 
- Barlow twins with SwinViT + semantic segmentation head, whithout using attention maps
-  Barlow twins with SwinViT + semantic segmentation head, whith attention maps, fusion 1
-  Barlow twins with SwinViT + semantic segmentation head, whith attention maps, fusion 2
-  DINO weights + semantic segmentation head, whith attention maps, fusion 2

We have to find various ways of combining the different attention maps and heads and use them in the semantic segmentation head. 

## Planning and workload : 

### Tasks : 

- [ ] Download dataset
- [ ] Take a look at google cloud platform and put the dataset inside
- [ ] Use pytorch lightning
- [ ] Implement Barlow Twins with resnet50 
- [ ] Implement Dino using hugging face transformers (?) / pytorch lighting? 
- [ ] BT SwinViT w/o attention
- [ ] BT SwinViT w attention
- [ ] Ablation studies
- [ ] Feature visualization, embeddings etc

# References and links : 
https://github.com/bytedance/ibot/blob/main/analysis/attention_map/visualize_attention.py 

https://github.com/facebookresearch/barlowtwins

# wandb key : 
1bd5c9f2298e5875d25866099bd98a8437c50cb6 


# Code to add : 

- [ ] Add AMP level : `trainer = Trainer(amp_level='O2')`
- [ ] Add SWA : `stochastic_weight_avg=True`

```
ğŸ“¦RecvisProject
 â”£ ğŸ“‚.vscode
 â”ƒ â”— ğŸ“œlaunch.json
 â”£ ğŸ“‚agents
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œbase.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œbase_contrastive.cpython-38.pyc
 â”ƒ â”ƒ â”— ğŸ“œtrainer.cpython-38.pyc
 â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”£ ğŸ“œbase.py
 â”ƒ â”£ ğŸ“œbase_contrastive.py
 â”ƒ â”— ğŸ“œtrainer.py
 â”£ ğŸ“‚assets
 â”ƒ â”£ ğŸ“‚VOC
 â”ƒ â”ƒ â”£ ğŸ“‚VOCdevkit
 â”ƒ â”ƒ â”ƒ â”— ğŸ“‚VOC2012
 â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“‚Annotations
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ2007_000027.xml
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ2007_000032.xml
 â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“‚ImageSets
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“‚Action
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œjumping_train.txt
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“‚Layout
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œtrain.txt
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œtrainval.txt
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”— ğŸ“œval.txt
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“‚Main
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œaeroplane_train.
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”— ğŸ“‚Segmentation
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œtrain.txt
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œtrainval.txt
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”— ğŸ“œval.txt
 â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“‚JPEGImages
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ2007_000027.jpg
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ2007_000032.jpg
 â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“‚SegmentationClass
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ2007_000032.png
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ2007_000033.png
 â”ƒ â”ƒ â”ƒ â”ƒ â”— ğŸ“‚SegmentationObject
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ2007_000032.png
 â”ƒ â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ2007_000033.png
 â”ƒ â”ƒ â”— ğŸ“œVOCtrainval_11-May-2012.tar
 â”ƒ â”— ğŸ“œ.keep
 â”£ ğŸ“‚config
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”— ğŸ“œhparams.cpython-38.pyc
 â”ƒ â”— ğŸ“œhparams.py
 â”£ ğŸ“‚datamodule
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”£ ğŸ“œVOCSegmentationDataModule.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œVOCsegmentationmodule.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”— ğŸ“œbase_data_module.cpython-38.pyc
 â”ƒ â”£ ğŸ“œVOCSegmentationDataModule.py
 â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”— ğŸ“œbase_data_module.py
 â”£ ğŸ“‚datasets
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”£ ğŸ“œBirdsDataloader.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œbase_dataloader.cpython-38.pyc
 â”ƒ â”ƒ â”— ğŸ“œbase_dataset.cpython-38.pyc
 â”ƒ â”£ ğŸ“œBirdsDataloader.py
 â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”£ ğŸ“œbase_dataloader.py
 â”ƒ â”— ğŸ“œbase_dataset.py
 â”£ ğŸ“‚graphs
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”— ğŸ“œweights_initializer.cpython-38.pyc
 â”ƒ â”£ ğŸ“‚losses
 â”ƒ â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œAngular.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œSubcenter_arcface.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œcustom_loss.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œAngular.py
 â”ƒ â”ƒ â”£ ğŸ“œSubcenter_arcface.py
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”ƒ â”— ğŸ“œcustom_loss.py
 â”ƒ â”£ ğŸ“‚models
 â”ƒ â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œContrastive_resnet50.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œContrastive_vit.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œbase.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œmobileNet.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œresnet50.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œvit.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“‚custom_layers
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”ƒ â”— ğŸ“œlayer_norm.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œlayer_norm.py
 â”ƒ â”ƒ â”£ ğŸ“œContrastive_resnet50.py
 â”ƒ â”ƒ â”£ ğŸ“œContrastive_vit.py
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”ƒ â”£ ğŸ“œbase.py
 â”ƒ â”ƒ â”£ ğŸ“œmobileNet.py
 â”ƒ â”ƒ â”£ ğŸ“œresnet50.py
 â”ƒ â”ƒ â”— ğŸ“œvit.py
 â”ƒ â”£ ğŸ“œ.DS_Store
 â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”— ğŸ“œweights_initializer.py
 â”£ ğŸ“‚model
 â”ƒ â”— ğŸ“œbase_voc.py
 â”£ ğŸ“‚models
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œbase.cpython-38.pyc
 â”ƒ â”ƒ â”— ğŸ“œbase_voc.cpython-38.pyc
 â”ƒ â”£ ğŸ“‚custom_layers
 â”ƒ â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œlayer_norm.cpython-38.pyc
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œunet_convs.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”ƒ â”£ ğŸ“œlayer_norm.py
 â”ƒ â”ƒ â”— ğŸ“œunet_convs.py
 â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”£ ğŸ“œbase.py
 â”ƒ â”— ğŸ“œbase_voc.py
 â”£ ğŸ“‚scripts
 â”ƒ â”— ğŸ“œsweep.yml
 â”£ ğŸ“‚test-sem-seg
 â”ƒ â”— ğŸ“‚jdv4pql6
 â”ƒ â”ƒ â”— ğŸ“‚checkpoints
 â”£ ğŸ“‚utils
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”£ ğŸ“œ__init__.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œagent_utils.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œcallbacks.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œfeature_visualization.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œlogger.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œmetrics.cpython-38.pyc
 â”ƒ â”ƒ â”£ ğŸ“œmisc.cpython-38.pyc
 â”ƒ â”ƒ â”— ğŸ“œtransforms.cpython-38.pyc
 â”ƒ â”£ ğŸ“œ__init__.py
 â”ƒ â”£ ğŸ“œagent_utils.py
 â”ƒ â”£ ğŸ“œcallbacks.py
 â”ƒ â”£ ğŸ“œfeature_visualization.py
 â”ƒ â”£ ğŸ“œlogger.py
 â”ƒ â”£ ğŸ“œmetrics.py
 â”ƒ â”£ ğŸ“œmisc.py
 â”ƒ â”— ğŸ“œtransforms.py
 â”£ ğŸ“‚wandb
 â”ƒ â”£ ğŸ“‚latest-run
 â”ƒ â”ƒ â”£ ğŸ“‚files
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œconda-environment.yaml
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œconfig.yaml
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œoutput.log
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œrequirements.txt
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œwandb-metadata.json
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œwandb-summary.json
 â”ƒ â”ƒ â”£ ğŸ“‚logs
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œdebug-internal.log
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œdebug.log
 â”ƒ â”ƒ â”£ ğŸ“‚tmp
 â”ƒ â”ƒ â”ƒ â”— ğŸ“‚code
 â”ƒ â”ƒ â”— ğŸ“œrun-1oueugp8.wandb
 â”ƒ â”£ ğŸ“‚run-20211220_180546-16kueqtx
 â”ƒ â”ƒ â”£ ğŸ“‚files
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œconda-environment.yaml
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œconfig.yaml
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œoutput.log
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œrequirements.txt
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œwandb-metadata.json
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œwandb-summary.json
 â”ƒ â”ƒ â”£ ğŸ“‚logs
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œdebug-internal.log
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œdebug.log
 â”ƒ â”ƒ â”£ ğŸ“‚tmp
 â”ƒ â”ƒ â”ƒ â”— ğŸ“‚code
 â”ƒ â”ƒ â”— ğŸ“œrun-16kueqtx.wandb 
 â”£ ğŸ“‚weights
 â”ƒ â”— ğŸ“œ.keep
 â”£ ğŸ“œ.git
 â”£ ğŸ“œ.gitignore
 â”£ ğŸ“œLICENSE
 â”£ ğŸ“œREADME.md
 â”£ ğŸ“œ__init__.py
 â”£ ğŸ“œmain.py
 â”£ ğŸ“œrequirements.txt
 â”— ğŸ“œrun.sh
 ```
 test